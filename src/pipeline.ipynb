{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/salveendutt/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt_tab')\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "from topic_modeling import *\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "random.seed(42)\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    \"\"\"Find synonyms for a given word.\"\"\"\n",
    "    synonyms = []\n",
    "    \n",
    "    # Get POS tag for the word\n",
    "    pos_tag = nltk.pos_tag([word])[0][1]\n",
    "    \n",
    "    # Map the POS tag to WordNet POS name\n",
    "    tag_map = {\n",
    "        'JJ': wordnet.ADJ,\n",
    "        'NN': wordnet.NOUN,\n",
    "        'NNS': wordnet.NOUN,\n",
    "        'RB': wordnet.ADV,\n",
    "        'VB': wordnet.VERB,\n",
    "        'VBD': wordnet.VERB,\n",
    "        'VBG': wordnet.VERB,\n",
    "        'VBN': wordnet.VERB,\n",
    "        'VBP': wordnet.VERB,\n",
    "        'VBZ': wordnet.VERB\n",
    "    }\n",
    "    \n",
    "    wordnet_pos = tag_map.get(pos_tag[0:2])\n",
    "    \n",
    "    if wordnet_pos:\n",
    "        for syn in wordnet.synsets(word, pos=wordnet_pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word and '_' not in lemma.name():\n",
    "                    synonyms.append(lemma.name())\n",
    "    \n",
    "    return list(set(synonyms))\n",
    "\n",
    "def get_antonyms(word):\n",
    "    \"\"\"Find antonyms for a given word using WordNet.\"\"\"\n",
    "    antonyms = []\n",
    "    \n",
    "    # Get POS tag for the word\n",
    "    pos_tag = nltk.pos_tag([word])[0][1]\n",
    "    \n",
    "    # Map the POS tag to WordNet POS name\n",
    "    tag_map = {\n",
    "        'JJ': wordnet.ADJ,\n",
    "        'NN': wordnet.NOUN,\n",
    "        'NNS': wordnet.NOUN,\n",
    "        'RB': wordnet.ADV,\n",
    "        'VB': wordnet.VERB,\n",
    "        'VBD': wordnet.VERB,\n",
    "        'VBG': wordnet.VERB,\n",
    "        'VBN': wordnet.VERB,\n",
    "        'VBP': wordnet.VERB,\n",
    "        'VBZ': wordnet.VERB\n",
    "    }\n",
    "    \n",
    "    wordnet_pos = tag_map.get(pos_tag[0:2])\n",
    "    \n",
    "    if wordnet_pos:\n",
    "        for syn in wordnet.synsets(word, pos=wordnet_pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    if antonym.name() != word and '_' not in antonym.name():\n",
    "                        antonyms.append(antonym.name())\n",
    "    \n",
    "    return list(set(antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_random_word(text, probability=0.1):\n",
    "    \"\"\"Add random words from WordNet to the text with a certain probability.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Preload synsets to avoid repeated expensive calls\n",
    "    synsets = list(wordnet.all_synsets())\n",
    "\n",
    "    def get_random_wordnet_word():\n",
    "        \"\"\"Get a random word from WordNet, ensuring it's a single-word noun or verb.\"\"\"\n",
    "        while True:\n",
    "            random_synset = random.choice(synsets)  # Avoid regenerating the list\n",
    "            word = random_synset.lemmas()[0].name()  # Get first lemma of the synset\n",
    "            if '_' not in word:  # Ensure single-word output\n",
    "                return word\n",
    "            \n",
    "    words = text.split()\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        modified_words.append(word)\n",
    "        if random.random() < probability:\n",
    "            random_word = get_random_wordnet_word()\n",
    "            modified_words.append(random_word)\n",
    "    \n",
    "    return ' '.join(modified_words)\n",
    "\n",
    "\n",
    "def add_random_character(text, probability=0.1):\n",
    "    \"\"\"Add random characters to words in text with a certain probability.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    words = text.split()\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if len(word) > 2 and random.random() < probability:\n",
    "            # Choose a random position to insert the character\n",
    "            position = random.randint(1, len(word) - 1)\n",
    "            # Choose a random lowercase letter\n",
    "            random_char = random.choice('abcdefghijklmnopqrstuvwxyz')\n",
    "            word = word[:position] + random_char + word[position:]\n",
    "        modified_words.append(word)\n",
    "    \n",
    "    return ' '.join(modified_words)\n",
    "\n",
    "def random_word_deletion(text, probability=0.1):\n",
    "    \"\"\"Randomly delete words from text with a certain probability.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    words = text.split()\n",
    "    if len(words) <= 3:  # Don't delete if text is too short\n",
    "        return text\n",
    "    \n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if random.random() >= probability:\n",
    "            modified_words.append(word)\n",
    "    \n",
    "    # Ensure we don't delete all words\n",
    "    if not modified_words:\n",
    "        modified_words = [random.choice(words)]\n",
    "    \n",
    "    return ' '.join(modified_words)\n",
    "\n",
    "def shuffle_sentences(text, probability=0.5):\n",
    "    \"\"\"Reorder sentences within a document with a certain probability.\"\"\"\n",
    "    if not isinstance(text, str) or len(text) < 10:\n",
    "        return text\n",
    "    \n",
    "    if random.random() < probability:\n",
    "        sentences = sent_tokenize(text)\n",
    "        if len(sentences) > 1:\n",
    "            random.shuffle(sentences)\n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def replace_with_synonym(text, probability=0.1):\n",
    "    \"\"\"Replace words with their synonyms with a certain probability.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isalpha() and len(word) > 3 and random.random() < probability:\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms:\n",
    "                modified_words.append(random.choice(synonyms))\n",
    "            else:\n",
    "                modified_words.append(word)\n",
    "        else:\n",
    "            modified_words.append(word)\n",
    "    \n",
    "    return ' '.join(modified_words)\n",
    "\n",
    "def create_adversarial_examples(text, probability=0.1, fallback_to_predefined=True):\n",
    "    \"\"\"\n",
    "    Create adversarial examples by replacing words with their antonyms from WordNet.\n",
    "    If WordNet doesn't have antonyms for a word and fallback_to_predefined is True,\n",
    "    uses a predefined dictionary of common antonyms.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Common antonym pairs as fallback\n",
    "    predefined_antonyms = {\n",
    "        'good': 'bad', 'bad': 'good', 'high': 'low', 'low': 'high',\n",
    "        'increase': 'decrease', 'decrease': 'increase', 'positive': 'negative',\n",
    "        'negative': 'positive', 'success': 'failure', 'failure': 'success',\n",
    "        'true': 'false', 'false': 'true', 'right': 'wrong', 'wrong': 'right',\n",
    "        'happy': 'sad', 'sad': 'happy', 'up': 'down', 'down': 'up',\n",
    "        'big': 'small', 'small': 'big', 'fast': 'slow', 'slow': 'fast',\n",
    "        'strong': 'weak', 'weak': 'strong', 'rich': 'poor', 'poor': 'rich',\n",
    "        'win': 'lose', 'lose': 'win', 'best': 'worst', 'worst': 'best',\n",
    "        'approve': 'reject', 'reject': 'approve', 'agree': 'disagree', 'disagree': 'agree',\n",
    "        'accept': 'deny', 'deny': 'accept', 'buy': 'sell', 'sell': 'buy'\n",
    "    }\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isalpha() and len(word) > 2 and random.random() < probability:\n",
    "            word_lower = word.lower()\n",
    "            antonyms = get_antonyms(word_lower)\n",
    "            \n",
    "            if antonyms:\n",
    "                # Use WordNet antonym\n",
    "                replacement = random.choice(antonyms)\n",
    "                \n",
    "                # Keep the original capitalization pattern\n",
    "                if word[0].isupper():\n",
    "                    replacement = replacement.capitalize()\n",
    "                \n",
    "                modified_words.append(replacement)\n",
    "            elif fallback_to_predefined and word_lower in predefined_antonyms:\n",
    "                # Fallback to predefined antonym if no WordNet antonyms exist\n",
    "                replacement = predefined_antonyms[word_lower]\n",
    "                \n",
    "                # Keep the original capitalization pattern\n",
    "                if word[0].isupper():\n",
    "                    replacement = replacement.capitalize()\n",
    "                \n",
    "                modified_words.append(replacement)\n",
    "            else:\n",
    "                modified_words.append(word)\n",
    "        else:\n",
    "            modified_words.append(word)\n",
    "    \n",
    "    return ' '.join(modified_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache a filtered list of simple words\n",
    "_CACHED_WORDS = None\n",
    "\n",
    "def _build_word_cache():\n",
    "    words = []\n",
    "    # Use noun synsets only for faster loading\n",
    "    for synset in list(wordnet.all_synsets()):\n",
    "        for lemma in synset.lemmas():\n",
    "            word = lemma.name()\n",
    "            if '_' not in word:  # only simple words\n",
    "                words.append(word)\n",
    "    return list(set(words))  # unique words\n",
    "\n",
    "def add_random_word(text, probability=0.1):\n",
    "    \"\"\"Add random words from WordNet to the text with a certain probability.\"\"\"\n",
    "    global _CACHED_WORDS\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "\n",
    "    # Build cache on first use\n",
    "    if _CACHED_WORDS is None:\n",
    "        _CACHED_WORDS = _build_word_cache()\n",
    "\n",
    "    words = text.split()\n",
    "    modified_words = []\n",
    "\n",
    "    for word in words:\n",
    "        modified_words.append(word)\n",
    "        if random.random() < probability:\n",
    "            random_word = random.choice(_CACHED_WORDS)\n",
    "            modified_words.append(random_word)\n",
    "\n",
    "    return ' '.join(modified_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AG News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_test = pd.read_csv('../data/AG News/test.csv')\n",
    "ag_train = pd.read_csv('../data/AG News/train.csv')\n",
    "\n",
    "# Define the mapping\n",
    "class_mapping = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Science\"}\n",
    "\n",
    "# Apply the mapping to the class column\n",
    "ag_test['Class'] = ag_test['Class Index'].replace(class_mapping)\n",
    "ag_train['Class'] = ag_train['Class Index'].replace(class_mapping)\n",
    "\n",
    "ag_news_baseline = ag_test['Description']\n",
    "ag_news_char_insertion = ag_test['Description'].apply(add_random_character)\n",
    "ag_news_word_deletion = ag_test['Description'].apply(random_word_deletion)\n",
    "ag_news_shuffle_sent = ag_test['Description'].apply(shuffle_sentences)\n",
    "ag_news_adversarial = ag_test['Description'].apply(create_adversarial_examples)\n",
    "ag_news_synonym = ag_test['Description'].apply(replace_with_synonym)\n",
    "ag_news_word_insertion = ag_test['Description'].apply(add_random_word)\n",
    "ag_news_combined = ag_test['Description'].apply(replace_with_synonym) \\\n",
    "    .apply(create_adversarial_examples) \\\n",
    "    .apply(add_random_word) \\\n",
    "    .apply(shuffle_sentences) \\\n",
    "    .apply(random_word_deletion) \\\n",
    "    .apply(add_random_character)\n",
    "\n",
    "ag_news_true_labels = ag_test['Class Index']\n",
    "\n",
    "ag_news = {\n",
    "    \"AG News\":(ag_news_baseline, ag_news_true_labels),\n",
    "    \"AG News Added Random Chars\":(ag_news_char_insertion, ag_news_true_labels),\n",
    "    \"AG News Random Word Deletion\":(ag_news_word_deletion, ag_news_true_labels),\n",
    "    \"AG News Shuffled Sentances\":(ag_news_shuffle_sent, ag_news_true_labels),\n",
    "    \"AG News Adversarial\":(ag_news_adversarial, ag_news_true_labels),\n",
    "    \"AG News Synonym\":(ag_news_synonym, ag_news_true_labels),\n",
    "    \"AG News Added Random Word\":(ag_news_word_insertion, ag_news_true_labels),\n",
    "    \"AG News Noisy\":(ag_news_combined, ag_news_true_labels),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LDA_4', 'LSI_4', 'NMF_4']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator = TopicModelOrchestrator()\n",
    "\n",
    "orchestrator.add_models_grid(\n",
    "    model_types=['LDA', 'LSI', 'NMF'],\n",
    "    param_grid={'n_topics': [4]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models on dataset: AG News\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Added Random Chars\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Random Word Deletion\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Shuffled Sentances\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Adversarial\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Synonym\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Added Random Word\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n",
      "Evaluating models on dataset: AG News Noisy\n",
      "  Evaluated model: LDA_4\n",
      "  Evaluated model: LSI_4\n",
      "  Evaluated model: NMF_4\n"
     ]
    }
   ],
   "source": [
    "results = orchestrator.evaluate(ag_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ARI Score</th>\n",
       "      <th>Topic Coherence</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "      <th>Reconstruction Error</th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.154719</td>\n",
       "      <td>0.533687</td>\n",
       "      <td>0.389324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.111348</td>\n",
       "      <td>0.631264</td>\n",
       "      <td>0.564310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.405050</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>0.473902</td>\n",
       "      <td>86.284560</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Added Random Chars</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.035902</td>\n",
       "      <td>0.378694</td>\n",
       "      <td>0.335707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Added Random Chars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.627627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Added Random Chars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.323788</td>\n",
       "      <td>0.710161</td>\n",
       "      <td>0.514478</td>\n",
       "      <td>86.497064</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Added Random Chars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Random Word Deletion</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.146251</td>\n",
       "      <td>0.459802</td>\n",
       "      <td>0.383968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Random Word Deletion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.106572</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.557175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Random Word Deletion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.391456</td>\n",
       "      <td>0.712067</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>86.339798</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Random Word Deletion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Shuffled Sentances</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.154719</td>\n",
       "      <td>0.533687</td>\n",
       "      <td>0.389324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Shuffled Sentances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.111348</td>\n",
       "      <td>0.631264</td>\n",
       "      <td>0.564310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Shuffled Sentances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.405050</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>0.473902</td>\n",
       "      <td>86.284560</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Shuffled Sentances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Adversarial</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.314761</td>\n",
       "      <td>0.529247</td>\n",
       "      <td>0.377528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.033675</td>\n",
       "      <td>0.620844</td>\n",
       "      <td>0.665497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.210658</td>\n",
       "      <td>0.701001</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>86.183547</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Adversarial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Synonym</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.281093</td>\n",
       "      <td>0.501447</td>\n",
       "      <td>0.389955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Synonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.040301</td>\n",
       "      <td>0.581179</td>\n",
       "      <td>0.668290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Synonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.199467</td>\n",
       "      <td>0.734391</td>\n",
       "      <td>0.608729</td>\n",
       "      <td>86.231278</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Synonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Added Random Word</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.039382</td>\n",
       "      <td>0.437140</td>\n",
       "      <td>0.342521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Added Random Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.523784</td>\n",
       "      <td>0.588163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Added Random Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.399264</td>\n",
       "      <td>0.600164</td>\n",
       "      <td>0.492833</td>\n",
       "      <td>86.470837</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Added Random Word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">AG News Noisy</th>\n",
       "      <th>LDA_4</th>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.354618</td>\n",
       "      <td>0.284381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LDA_4</td>\n",
       "      <td>AG News Noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSI_4</th>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.713197</td>\n",
       "      <td>0.673011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSI_4</td>\n",
       "      <td>AG News Noisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF_4</th>\n",
       "      <td>0.229944</td>\n",
       "      <td>0.648197</td>\n",
       "      <td>0.600032</td>\n",
       "      <td>86.618453</td>\n",
       "      <td>NMF_4</td>\n",
       "      <td>AG News Noisy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ARI Score  Topic Coherence  \\\n",
       "Dataset                                                          \n",
       "AG News                      LDA_4   0.154719         0.533687   \n",
       "                             LSI_4   0.111348         0.631264   \n",
       "                             NMF_4   0.405050         0.722596   \n",
       "AG News Added Random Chars   LDA_4   0.035902         0.378694   \n",
       "                             LSI_4   0.005190         0.602564   \n",
       "                             NMF_4   0.323788         0.710161   \n",
       "AG News Random Word Deletion LDA_4   0.146251         0.459802   \n",
       "                             LSI_4   0.106572         0.531868   \n",
       "                             NMF_4   0.391456         0.712067   \n",
       "AG News Shuffled Sentances   LDA_4   0.154719         0.533687   \n",
       "                             LSI_4   0.111348         0.631264   \n",
       "                             NMF_4   0.405050         0.722596   \n",
       "AG News Adversarial          LDA_4   0.314761         0.529247   \n",
       "                             LSI_4   0.033675         0.620844   \n",
       "                             NMF_4   0.210658         0.701001   \n",
       "AG News Synonym              LDA_4   0.281093         0.501447   \n",
       "                             LSI_4   0.040301         0.581179   \n",
       "                             NMF_4   0.199467         0.734391   \n",
       "AG News Added Random Word    LDA_4   0.039382         0.437140   \n",
       "                             LSI_4   0.005186         0.523784   \n",
       "                             NMF_4   0.399264         0.600164   \n",
       "AG News Noisy                LDA_4   0.002210         0.354618   \n",
       "                             LSI_4   0.006085         0.713197   \n",
       "                             NMF_4   0.229944         0.648197   \n",
       "\n",
       "                                    Cosine Similarity  Reconstruction Error  \\\n",
       "Dataset                                                                       \n",
       "AG News                      LDA_4           0.389324                   NaN   \n",
       "                             LSI_4           0.564310                   NaN   \n",
       "                             NMF_4           0.473902             86.284560   \n",
       "AG News Added Random Chars   LDA_4           0.335707                   NaN   \n",
       "                             LSI_4           0.627627                   NaN   \n",
       "                             NMF_4           0.514478             86.497064   \n",
       "AG News Random Word Deletion LDA_4           0.383968                   NaN   \n",
       "                             LSI_4           0.557175                   NaN   \n",
       "                             NMF_4           0.474443             86.339798   \n",
       "AG News Shuffled Sentances   LDA_4           0.389324                   NaN   \n",
       "                             LSI_4           0.564310                   NaN   \n",
       "                             NMF_4           0.473902             86.284560   \n",
       "AG News Adversarial          LDA_4           0.377528                   NaN   \n",
       "                             LSI_4           0.665497                   NaN   \n",
       "                             NMF_4           0.604508             86.183547   \n",
       "AG News Synonym              LDA_4           0.389955                   NaN   \n",
       "                             LSI_4           0.668290                   NaN   \n",
       "                             NMF_4           0.608729             86.231278   \n",
       "AG News Added Random Word    LDA_4           0.342521                   NaN   \n",
       "                             LSI_4           0.588163                   NaN   \n",
       "                             NMF_4           0.492833             86.470837   \n",
       "AG News Noisy                LDA_4           0.284381                   NaN   \n",
       "                             LSI_4           0.673011                   NaN   \n",
       "                             NMF_4           0.600032             86.618453   \n",
       "\n",
       "                                    Model                       Dataset  \n",
       "Dataset                                                                  \n",
       "AG News                      LDA_4  LDA_4                       AG News  \n",
       "                             LSI_4  LSI_4                       AG News  \n",
       "                             NMF_4  NMF_4                       AG News  \n",
       "AG News Added Random Chars   LDA_4  LDA_4    AG News Added Random Chars  \n",
       "                             LSI_4  LSI_4    AG News Added Random Chars  \n",
       "                             NMF_4  NMF_4    AG News Added Random Chars  \n",
       "AG News Random Word Deletion LDA_4  LDA_4  AG News Random Word Deletion  \n",
       "                             LSI_4  LSI_4  AG News Random Word Deletion  \n",
       "                             NMF_4  NMF_4  AG News Random Word Deletion  \n",
       "AG News Shuffled Sentances   LDA_4  LDA_4    AG News Shuffled Sentances  \n",
       "                             LSI_4  LSI_4    AG News Shuffled Sentances  \n",
       "                             NMF_4  NMF_4    AG News Shuffled Sentances  \n",
       "AG News Adversarial          LDA_4  LDA_4           AG News Adversarial  \n",
       "                             LSI_4  LSI_4           AG News Adversarial  \n",
       "                             NMF_4  NMF_4           AG News Adversarial  \n",
       "AG News Synonym              LDA_4  LDA_4               AG News Synonym  \n",
       "                             LSI_4  LSI_4               AG News Synonym  \n",
       "                             NMF_4  NMF_4               AG News Synonym  \n",
       "AG News Added Random Word    LDA_4  LDA_4     AG News Added Random Word  \n",
       "                             LSI_4  LSI_4     AG News Added Random Word  \n",
       "                             NMF_4  NMF_4     AG News Added Random Word  \n",
       "AG News Noisy                LDA_4  LDA_4                 AG News Noisy  \n",
       "                             LSI_4  LSI_4                 AG News Noisy  \n",
       "                             NMF_4  NMF_4                 AG News Noisy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
