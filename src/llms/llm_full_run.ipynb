{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from langchain_community.llms import Ollama\n",
    "random.seed(42)\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AG News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_test = pd.read_csv('../../data/AG News/test.csv')\n",
    "ag_train = pd.read_csv('../../data/AG News/train.csv')\n",
    "\n",
    "# Define the mapping\n",
    "class_to_text_mapping = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Science\"}\n",
    "text_to_class_mapping = {'World': 1, 'Sports': 2, 'Business': 3, 'Science': 4}\n",
    "\n",
    "# Apply the mapping to the class column\n",
    "# ag_test['Class'] = ag_test['Class Index'].replace(class_mapping)\n",
    "# ag_train['Class'] = ag_train['Class Index'].replace(class_mapping)\n",
    "\n",
    "ag_news_train_baseline = ag_train['Description']\n",
    "ag_news_train_true_labels = ag_train['Class Index']\n",
    "\n",
    "sampled = ag_news_train_baseline.sample(1000, random_state=42)\n",
    "ag_news_train_baseline = sampled\n",
    "ag_news_train_true_labels = ag_news_train_true_labels.loc[sampled.index]\n",
    "\n",
    "sampled_indices = ag_test.sample(3600, random_state=42).index\n",
    "ag_news_baseline = ag_test.loc[sampled_indices, 'Description']\n",
    "ag_news_true_labels = ag_test.loc[sampled_indices, 'Class Index']\n",
    "\n",
    "ag_news_train = {\n",
    "    \"AG News\":(ag_news_train_baseline, ag_news_train_true_labels),\n",
    "}\n",
    "\n",
    "ag_news = {\n",
    "    \"AG News\":(ag_news_baseline, ag_news_true_labels),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>true_labels_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>Schering-Plough Corporation has announced that...</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>The UN tribunal in The Hague says it will impo...</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>AP - Don't question Pedro Martinez anymore. Fa...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>CARDIFF -- Championship leader Sebastien Loeb ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221</th>\n",
       "      <td>In New York, San Francisco, and Washington, D....</td>\n",
       "      <td>4</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>A company board member testifies in trial that...</td>\n",
       "      <td>4</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>Joe Nemechek wasn #39;t surprised to be back a...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>AP - Turkey's parliament adjourned Saturday wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>We've got two more entries this week in the ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>Polk County will retain its position at the he...</td>\n",
       "      <td>3</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  true_labels  \\\n",
       "1615  Schering-Plough Corporation has announced that...            3   \n",
       "1049  The UN tribunal in The Hague says it will impo...            1   \n",
       "4626  AP - Don't question Pedro Martinez anymore. Fa...            2   \n",
       "2019  CARDIFF -- Championship leader Sebastien Loeb ...            2   \n",
       "3221  In New York, San Francisco, and Washington, D....            4   \n",
       "...                                                 ...          ...   \n",
       "3217  A company board member testifies in trial that...            4   \n",
       "2995  Joe Nemechek wasn #39;t surprised to be back a...            2   \n",
       "2022  AP - Turkey's parliament adjourned Saturday wi...            1   \n",
       "6757  We've got two more entries this week in the ca...            4   \n",
       "4518  Polk County will retain its position at the he...            3   \n",
       "\n",
       "     true_labels_text  \n",
       "1615         Business  \n",
       "1049            World  \n",
       "4626           Sports  \n",
       "2019           Sports  \n",
       "3221          Science  \n",
       "...               ...  \n",
       "3217          Science  \n",
       "2995           Sports  \n",
       "2022            World  \n",
       "6757          Science  \n",
       "4518         Business  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Series to DataFrame\n",
    "df = pd.DataFrame({'text': ag_news_baseline})\n",
    "df['true_labels'] = ag_news_true_labels\n",
    "df['true_labels_text'] = df['true_labels'].map(class_to_text_mapping)\n",
    "df = df.sample(100, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import torch\n",
    "from flair.models import TARSClassifier\n",
    "from flair.data import Sentence\n",
    "from typing import List, Optional, Union\n",
    "class IClasificationModel(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        self.assigned_topics = None\n",
    "        self.topic_distributions = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_classes(self, documents): \n",
    "        pass\n",
    "\n",
    "    @abstractmethod    \n",
    "    def fit_model(self, train_data_X, train_data_y):\n",
    "        pass\n",
    "\n",
    "    def evaluate(self, documents, true_labels: pd.DataFrame=None):\n",
    "        predictions = self.predict_classes(documents)\n",
    "        accuracy = accuracy_score(predictions, true_labels)\n",
    "        f1 = f1_score(predictions, true_labels, average='weighted')\n",
    "        precision = precision_score(predictions, true_labels, average='weighted')\n",
    "        recall = recall_score(predictions, true_labels, average='weighted')\n",
    "\n",
    "        return {\n",
    "            'Accuracy': accuracy,\n",
    "            'F1 Score': f1,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall\n",
    "        }\n",
    "\n",
    "\n",
    "class TARSZeroShotModel(IClasificationModel):\n",
    "    def __init__(self, model_name: str = 'tars-base'):\n",
    "        super().__init__()\n",
    "        self.model = TARSClassifier.load(model_name)\n",
    "        self.model.add_and_switch_to_new_task(\"ZeroShot\", label_dictionary=['World', 'Sports', 'Business', 'Science'], label_type=\"classification\")\n",
    "        \n",
    "    def fit_model(self, train_data_X, train_data_y):\n",
    "        pass\n",
    "        \n",
    "    def predict_classes(self, documents):\n",
    "            \n",
    "        predictions = []\n",
    "        \n",
    "        for doc in documents.tolist():\n",
    "            sentence = Sentence(doc)\n",
    "            self.model.predict(sentence)\n",
    "            if sentence.labels:\n",
    "                prediction = sentence.labels[0].value\n",
    "            else:\n",
    "                prediction = \"Unknown\"\n",
    "                \n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-21 23:10:52,952 TARS initialized without a task. You need to call .add_and_switch_to_new_task() before training this model\n",
      "Predicting topics with TARS zero-shot model...\n"
     ]
    }
   ],
   "source": [
    "m = TARSZeroShotModel()\n",
    "# Predict topics using TARS zero-shot model\n",
    "print(\"Predicting topics with TARS zero-shot model...\")\n",
    "candidate_labels = list(class_to_text_mapping.values())  # ['World', 'Sports', 'Business', 'Science']\n",
    "predictions = m.predict_classes(df['text'])\n",
    "\n",
    "# Add predictions to dataframe\n",
    "df['tars_predicted'] = predictions\n",
    "\n",
    "# Convert text predictions to class indices for evaluation\n",
    "predicted_indices = [text_to_class_mapping.get(label, -1) for label in predictions]\n",
    "\n",
    "# # Calculate metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARS Zero-Shot Model Performance:\n",
      "Accuracy: 0.7500\n",
      "F1 Score: 0.7636\n",
      "Precision: 0.9373\n",
      "Recall: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(df['true_labels'], predicted_indices)\n",
    "f1 = f1_score(df['true_labels'], predicted_indices, average='weighted')\n",
    "precision = precision_score(df['true_labels'], predicted_indices, average='weighted')\n",
    "recall = recall_score(df['true_labels'], predicted_indices, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"TARS Zero-Shot Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'World', 'Sports', 'Science'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = df['true_labels_text'].unique()\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics(input_df, topics, llm=None, checkpoint_interval=300):\n",
    "    if llm is None:\n",
    "        raise ValueError(\"LLM instance must be provided\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    # Initialize Topic column with 'Unknown'\n",
    "    df['Predicted Topic'] = 'Unknown'\n",
    "    \n",
    "    # Process each news item individually with progress bar\n",
    "    for idx in tqdm(range(len(df)), desc=\"Assigning topics\"):\n",
    "        news_item = df.iloc[idx]['text']\n",
    "        \n",
    "        # Generate prompt for current item\n",
    "        prompt_assigning_prompt = f'''You are provided with news and helping to classify them based on the topics.\n",
    "Please assign the news to the topics provided. Return only the name of the topic for the respective news.\n",
    "News can be found in tripletick block: ```{news_item}```\n",
    "Topics to choose from: {topics}\n",
    "Please return ONLY the topic name. DO NOT OUTPUT any additional text, quotes, or formatting.'''\n",
    "        \n",
    "        try:\n",
    "            # Get assignment for current item\n",
    "            result = llm.invoke(prompt_assigning_prompt, temperature=0.0)\n",
    "            \n",
    "            # Clean the result\n",
    "            result = result.strip()\n",
    "            if result.startswith('```') and result.endswith('```'):\n",
    "                result = result[3:-3].strip()\n",
    "            \n",
    "            # Update the DataFrame with the assigned topic\n",
    "            df.iloc[idx, df.columns.get_loc('Predicted Topic')] = result\n",
    "            \n",
    "            # Save checkpoint every checkpoint_interval rows\n",
    "            if (idx + 1) % checkpoint_interval == 0:\n",
    "                checkpoint_filename = f'outputs/news_assigned_checkpoint_{idx + 1}.csv'\n",
    "                df.to_csv(checkpoint_filename, index=False)\n",
    "                print(f\"\\nCheckpoint saved: {checkpoint_filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing item {idx}: {str(e)}\")\n",
    "            print(f\"Result received: {result}\")\n",
    "            continue\n",
    "    \n",
    "    # Save final results\n",
    "    final_filename = '../../outputs/llm_full/news_assigned_final.csv'\n",
    "    df.to_csv(final_filename, index=False)\n",
    "    print(f\"\\nFinal results saved: {final_filename}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88295d39c41b4455bf8d99f322adbc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning topics:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results saved: checkpoints/news_assigned_final.csv\n"
     ]
    }
   ],
   "source": [
    "news_assigned = assign_topics(\n",
    "    df,\n",
    "    topics=str(topics),\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_assigned[[news_assigned['Predicted Topic'] == news_assigned['true_labels_text']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8300\n",
      "F1 Score: 0.8117\n",
      "Precision: 0.8562\n",
      "Recall: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Convert predicted topics to numeric labels using the mapping\n",
    "predicted_labels = news_assigned['Predicted Topic'].map(text_to_class_mapping).fillna(-1).astype(int)\n",
    "true_labels = news_assigned['true_labels']\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
