{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RUN WHEN RUNNING FOR THE FIRST TIME\n",
    "# !ollama pull gemma3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from langchain_ollama import OllamaLLM\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_metrics(df, predicted_col='Predicted Topic Index', true_col='Class Index'):\n",
    "    \"\"\"\n",
    "    Calculate classification metrics for news topic prediction.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the predictions and true labels\n",
    "        predicted_col: Column name for predicted labels (text format)\n",
    "        true_col: Column name for true labels (numeric format)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of calculated metrics\n",
    "    \"\"\"\n",
    "    true_labels = df[true_col].tolist()\n",
    "    predicted_labels = df[predicted_col].tolist()\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topics(input_df, topics, mapping, llm=None, output_path=None):\n",
    "    if llm is None:\n",
    "        raise ValueError(\"LLM instance must be provided\")\n",
    "    if output_path is None:\n",
    "        raise ValueError(\"Output path must be provided\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df = input_df.copy()\n",
    "    \n",
    "    # Initialize Topic column with 'Unknown'\n",
    "    df['Predicted Topic'] = 'Unknown'\n",
    "    \n",
    "    # Process each news item individually with progress bar\n",
    "    for idx in tqdm(range(len(df)), desc=\"Assigning topics\"):\n",
    "        news_item = df.iloc[idx]['Description']\n",
    "        \n",
    "        # Generate prompt for current item\n",
    "        prompt_assigning_prompt = f'''You are provided with news and helping to classify them based on the topics.\n",
    "Please assign the news to the topics provided. Return only the name of the topic for the respective news.\n",
    "News can be found in tripletick block: ```{news_item}```\n",
    "Topics to choose from: {topics}\n",
    "Please return ONLY the topic name. DO NOT OUTPUT any additional text, quotes, or formatting. Only 1 topic  should be returned.'''\n",
    "        \n",
    "        try:\n",
    "            result = llm.invoke(prompt_assigning_prompt)\n",
    "            # Clean the result\n",
    "            result = result.strip()\n",
    "            if result.startswith('```') and result.endswith('```'):\n",
    "                result = result[3:-3].strip()\n",
    "            \n",
    "            # Update the DataFrame with the assigned topic\n",
    "            df.iloc[idx, df.columns.get_loc('Predicted Topic')] = result\n",
    "                            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing item {idx}: {str(e)}\")\n",
    "            print(f\"Result received: {result}\")\n",
    "            continue\n",
    "    df['Predicted Topic Index'] = df['Predicted Topic'].map(mapping)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nFinal results saved: {output_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"gemma3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AG News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_per_class = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_train = pd.read_csv('../../data/AG News/train.csv')\n",
    "\n",
    "class_to_text_mapping = {1: \"World\", 2: \"Sports\", 3: \"Business\", 4: \"Science\"}\n",
    "text_to_class_mapping = {'World': 1, 'Sports': 2, 'Business': 3, 'Science': 4}\n",
    "ag_train['Class'] = ag_train['Class Index'].map(class_to_text_mapping)\n",
    "\n",
    "# CREATING A SAMPLE TRAIN SET\n",
    "ag_train_world = ag_train[ag_train['Class Index'] == 1].sample(sample_size_per_class, random_state=42)\n",
    "ag_train_sports = ag_train[ag_train['Class Index'] == 2].sample(sample_size_per_class, random_state=42)\n",
    "ag_train_business = ag_train[ag_train['Class Index'] == 3].sample(sample_size_per_class, random_state=42)\n",
    "ag_train_science = ag_train[ag_train['Class Index'] == 4].sample(sample_size_per_class, random_state=42)\n",
    "\n",
    "# Combine the four dataframes of different categories\n",
    "ag_train = pd.concat([ag_train_world, \n",
    "                            ag_train_sports, \n",
    "                            ag_train_business, \n",
    "                            ag_train_science], \n",
    "                           ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataframe\n",
    "ag_train = ag_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Reset the index\n",
    "ag_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "topics_ag_news = ag_train['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5cb6ad612049eaa513375645a89926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning topics:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results saved: ../../data/AG News/train_from_llm.csv\n"
     ]
    }
   ],
   "source": [
    "ag_news_output = assign_topics(\n",
    "    ag_train,\n",
    "    topics=str(topics_ag_news),\n",
    "    mapping=text_to_class_mapping,\n",
    "    llm=llm,\n",
    "    output_path='../../data/AG News/train_from_llm.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8125\n",
      "F1 Score: 0.7970\n",
      "Precision: 0.8658\n",
      "Recall: 0.8125\n"
     ]
    }
   ],
   "source": [
    "ag_metrics = calculate_metrics(ag_news_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBC News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_full = pd.read_csv('../../data/BBC News/BBC News Train.csv')\n",
    "bbc_full = bbc_full.rename(columns={'Category': 'Class', 'Text': 'Description'})\n",
    "\n",
    "bbc_class_to_index = {\n",
    "    'business': 1,\n",
    "    'tech': 2,\n",
    "    'entertainment': 3,\n",
    "    'politics': 4,\n",
    "    'sport': 5\n",
    "}\n",
    "\n",
    "bbc_index_to_class = {\n",
    "    1: 'business',\n",
    "    2: 'tech',\n",
    "    3: 'entertainment',\n",
    "    4: 'politics',\n",
    "    5: 'sport'\n",
    "}\n",
    "\n",
    "bbc_full['Class Index'] = bbc_full['Class'].map(bbc_class_to_index)\n",
    "\n",
    "\n",
    "bbc_train_business = bbc_full[bbc_full['Class Index'] == 1].sample(sample_size_per_class, random_state=42)\n",
    "bbc_train_tech = bbc_full[bbc_full['Class Index'] == 2].sample(sample_size_per_class, random_state=42)\n",
    "bbc_train_entertainment = bbc_full[bbc_full['Class Index'] == 3].sample(sample_size_per_class, random_state=42)\n",
    "bbc_train_politics = bbc_full[bbc_full['Class Index'] == 4].sample(sample_size_per_class, random_state=42)\n",
    "bbc_train_sport = bbc_full[bbc_full['Class Index'] == 5].sample(sample_size_per_class, random_state=42)\n",
    "\n",
    "# Create a test set by excluding the training samples\n",
    "bbc_train_indices = pd.concat([\n",
    "    bbc_train_business,\n",
    "    bbc_train_tech, \n",
    "    bbc_train_entertainment,\n",
    "    bbc_train_politics,\n",
    "    bbc_train_sport\n",
    "]).index\n",
    "# Create test set by excluding training indices\n",
    "bbc_test = bbc_full.drop(bbc_train_indices).reset_index(drop=True)\n",
    "bbc_test.to_csv('../../data/BBC News/test.csv', index=False)\n",
    "\n",
    "# Combine the four dataframes of different categories\n",
    "bbc_train = pd.concat([\n",
    "    bbc_train_business, \n",
    "    bbc_train_tech, \n",
    "    bbc_train_entertainment, \n",
    "    bbc_train_politics, \n",
    "    bbc_train_sport\n",
    "], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataframe\n",
    "bbc_train = bbc_train.sample(frac=1, random_state=42)\n",
    "bbc_train = bbc_train.reset_index(drop=True)\n",
    "\n",
    "topics_bbc_news = bbc_train['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c743b8edce4bdc973e684d4e022fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning topics:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results saved: ../../data/BBC News/train_from_llm.csv\n"
     ]
    }
   ],
   "source": [
    "bbc_news_output = assign_topics(\n",
    "    bbc_train,\n",
    "    topics=str(topics_bbc_news),\n",
    "    llm=llm,\n",
    "    mapping=bbc_class_to_index,\n",
    "    output_path='../../data/BBC News/train_from_llm.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8800\n",
      "F1 Score: 0.8777\n",
      "Precision: 0.8846\n",
      "Recall: 0.8800\n"
     ]
    }
   ],
   "source": [
    "bbc_metrics = calculate_metrics(bbc_news_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 News Group Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
